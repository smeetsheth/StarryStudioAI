{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28e6c296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cassandra-driver\n",
      "  Obtaining dependency information for cassandra-driver from https://files.pythonhosted.org/packages/f8/26/adc5beac60c373733569868ee1843691fae5d9d8cd07a4907e7c4a55bdaa/cassandra_driver-3.29.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading cassandra_driver-3.29.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Collecting geomet<0.3,>=0.1 (from cassandra-driver)\n",
      "  Obtaining dependency information for geomet<0.3,>=0.1 from https://files.pythonhosted.org/packages/c9/81/156ca48f950f833ddc392f8e3677ca50a18cb9d5db38ccb4ecea55a9303f/geomet-0.2.1.post1-py3-none-any.whl.metadata\n",
      "  Downloading geomet-0.2.1.post1-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: click in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.0.4)\n",
      "Requirement already satisfied: six in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from geomet<0.3,>=0.1->cassandra-driver) (1.16.0)\n",
      "Downloading cassandra_driver-3.29.2-cp311-cp311-macosx_11_0_arm64.whl (364 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.1/364.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: geomet, cassandra-driver\n",
      "Successfully installed cassandra-driver-3.29.2 geomet-0.2.1.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install cassandra-driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d68da82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ace-tools\n",
      "  Obtaining dependency information for ace-tools from https://files.pythonhosted.org/packages/27/c4/402d3ae2ecbfe72fbdcb2769f55580f1c54a3ca110c44e1efc034516a499/ace_tools-0.0-py3-none-any.whl.metadata\n",
      "  Downloading ace_tools-0.0-py3-none-any.whl.metadata (300 bytes)\n",
      "Downloading ace_tools-0.0-py3-none-any.whl (1.1 kB)\n",
      "Installing collected packages: ace-tools\n",
      "Successfully installed ace-tools-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ace-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39adf660",
   "metadata": {},
   "source": [
    "### Combining data for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4055c769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified Data for Embedding:\n",
      "              ID  Source_Type  Source_ID  \\\n",
      "0  Instruction-1  Instruction          1   \n",
      "1  Instruction-2  Instruction          2   \n",
      "2  Instruction-3  Instruction          3   \n",
      "3  Instruction-4  Instruction          4   \n",
      "4  Instruction-5  Instruction          5   \n",
      "\n",
      "                                 Text_Representation  \n",
      "0  Create a header of a personal portfolio websit...  \n",
      "1  Create a header of a Photography Portfolio Web...  \n",
      "2  Create a header for a Portfolio website under ...  \n",
      "3  Create a header for a portfolio website in the...  \n",
      "4  Create a header of a Personal Portfolio Websit...  \n",
      "Data saved to /Users/smeetsheth/Documents/Data 298B/RAG Implemenation/CSV Files/unified_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths for existing CSVs\n",
    "#base_path = \"/Users/bhavikpatel/Desktop/RAG/RAG_Data/\"  # Update to your directory\n",
    "import pandas as pd\n",
    "\n",
    "# Load the individual CSV files\n",
    "instructions_df = pd.read_csv(\"/Users/smeetsheth/Documents/Data 298B/RAG Implemenation/CSV Files/instructions.csv\")\n",
    "html_components_df = pd.read_csv(\"/Users/smeetsheth/Documents/Data 298B/RAG Implemenation/CSV Files/html_components.csv\")\n",
    "css_styles_df = pd.read_csv(\"/Users/smeetsheth/Documents/Data 298B/RAG Implemenation/CSV Files/css_styles.csv\")\n",
    "\n",
    "# Create a list to hold the unified rows\n",
    "unified_data = []\n",
    "\n",
    "# Add Instructions to the unified data\n",
    "for _, row in instructions_df.iterrows():\n",
    "    unified_data.append({\n",
    "        \"ID\": f\"Instruction-{row['instruction_id']}\",\n",
    "        \"Source_Type\": \"Instruction\",\n",
    "        \"Source_ID\": row[\"instruction_id\"],\n",
    "        \"Text_Representation\": row[\"text\"]\n",
    "    })\n",
    "\n",
    "# Add HTML Components to the unified data\n",
    "for _, row in html_components_df.iterrows():\n",
    "    text_representation = f\"Name: {row['name']}, Attributes: {row['attributes']}, Context: {row['component_context']}.\"\n",
    "    unified_data.append({\n",
    "        \"ID\": f\"HTML-{row['component_id']}\",\n",
    "        \"Source_Type\": \"HTML_Component\",\n",
    "        \"Source_ID\": row[\"component_id\"],\n",
    "        \"Text_Representation\": text_representation\n",
    "    })\n",
    "\n",
    "# Add CSS Styles to the unified data\n",
    "for _, row in css_styles_df.iterrows():\n",
    "    text_representation = (f\"Selector: {row['selector']}, Properties: {row['properties']}, \"\n",
    "                           f\"Context: {row['description']}.\")\n",
    "    unified_data.append({\n",
    "        \"ID\": f\"CSS-{row['style_id']}\",\n",
    "        \"Source_Type\": \"CSS_Style\",\n",
    "        \"Source_ID\": row[\"style_id\"],\n",
    "        \"Text_Representation\": text_representation\n",
    "    })\n",
    "\n",
    "# Convert the unified data to a DataFrame\n",
    "unified_df = pd.DataFrame(unified_data)\n",
    "\n",
    "# Save the unified DataFrame to a CSV file\n",
    "output_path = \"/Users/smeetsheth/Documents/Data 298B/RAG Implemenation/CSV Files/unified_data.csv\"\n",
    "unified_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the first few rows of the dataframe to verify the content\n",
    "print(\"Unified Data for Embedding:\")\n",
    "print(unified_df.head())\n",
    "\n",
    "# Confirm the path of the saved file\n",
    "print(f\"Data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ba9988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified CSV loaded successfully. Here's a preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source_Type</th>\n",
       "      <th>Source_ID</th>\n",
       "      <th>Text_Representation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Instruction-1</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>Create a header of a personal portfolio websit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Instruction-2</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>2</td>\n",
       "      <td>Create a header of a Photography Portfolio Web...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Instruction-3</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>3</td>\n",
       "      <td>Create a header for a Portfolio website under ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Instruction-4</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>4</td>\n",
       "      <td>Create a header for a portfolio website in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Instruction-5</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>5</td>\n",
       "      <td>Create a header of a Personal Portfolio Websit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID  Source_Type  Source_ID  \\\n",
       "0  Instruction-1  Instruction          1   \n",
       "1  Instruction-2  Instruction          2   \n",
       "2  Instruction-3  Instruction          3   \n",
       "3  Instruction-4  Instruction          4   \n",
       "4  Instruction-5  Instruction          5   \n",
       "\n",
       "                                 Text_Representation  \n",
       "0  Create a header of a personal portfolio websit...  \n",
       "1  Create a header of a Photography Portfolio Web...  \n",
       "2  Create a header for a Portfolio website under ...  \n",
       "3  Create a header for a portfolio website in the...  \n",
       "4  Create a header of a Personal Portfolio Websit...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names:\n",
      "['ID', 'Source_Type', 'Source_ID', 'Text_Representation']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the unified CSV file\n",
    "file_path = \"/Users/smeetsheth/Documents/Data 298B/RAG Implemenation/CSV Files/unified_data.csv\"  # Update this path to the actual location of the file\n",
    "try:\n",
    "    unified_df = pd.read_csv(file_path)\n",
    "    print(\"Unified CSV loaded successfully. Here's a preview:\")\n",
    "    display(unified_df.head())\n",
    "    print(\"\\nColumn Names:\")\n",
    "    print(unified_df.columns.tolist())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2b0fb5",
   "metadata": {},
   "source": [
    "### Creating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117ba3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (2.7.0)\n",
      "Requirement already satisfied: pandas in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.46.1)\n",
      "Requirement already satisfied: tqdm in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: numpy in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: filelock in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: requests in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: sympy in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.20.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b227bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4dfbe1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ID  Source_Type  Source_ID  \\\n",
      "0  Instruction-1  Instruction          1   \n",
      "1  Instruction-2  Instruction          2   \n",
      "2  Instruction-3  Instruction          3   \n",
      "3  Instruction-4  Instruction          4   \n",
      "4  Instruction-5  Instruction          5   \n",
      "\n",
      "                                 Text_Representation  \n",
      "0  Create a header of a personal portfolio websit...  \n",
      "1  Create a header of a Photography Portfolio Web...  \n",
      "2  Create a header for a Portfolio website under ...  \n",
      "3  Create a header for a portfolio website in the...  \n",
      "4  Create a header of a Personal Portfolio Websit...  \n"
     ]
    }
   ],
   "source": [
    "# Path to the structured CSV file\n",
    "file_path = \"/Users/smeetsheth/Documents/Data 298B/RAG Implemenation/CSV Files/unified_data.csv\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display a snippet of the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8129ada",
   "metadata": {},
   "source": [
    "### Loading SBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0869ac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the SBERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Verify model is loaded\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc090b75",
   "metadata": {},
   "source": [
    "### Generating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64483c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for the 'Text_Representation' column\n",
    "data['Embedding'] = data['Text_Representation'].apply(lambda x: model.encode(str(x)).tolist())\n",
    "\n",
    "# Confirm embeddings are generated\n",
    "print(\"Embeddings generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040456d",
   "metadata": {},
   "source": [
    "### Saving the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "657d3ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with embeddings saved to: /Users/smeetsheth/Documents/Data 298B/RAG Implemenation/CSV Files/unified_data_with_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame with embeddings to a new CSV file\n",
    "output_path = \"/Users/smeetsheth/Documents/Data 298B/RAG Implemenation/CSV Files/unified_data_with_embeddings.csv\"\n",
    "data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Data with embeddings saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9826aec8",
   "metadata": {},
   "source": [
    "### Testing the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0405b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f6443d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Matches:\n",
      "   Source_ID  Combined_Similarity\n",
      "0        143             0.353227\n",
      "1        230             0.352280\n",
      "2        139             0.342654\n",
      "3        192             0.340401\n",
      "4        128             0.339958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r_/7p_x_zfn6m17765l8kqlmk9c0000gn/T/ipykernel_43908/1083413926.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  instructions['Similarity'] = cosine_similarity(query_embedding, np.vstack(instructions['Embedding'])).flatten()\n",
      "/var/folders/r_/7p_x_zfn6m17765l8kqlmk9c0000gn/T/ipykernel_43908/1083413926.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  html_components['Similarity'] = cosine_similarity(query_embedding, np.vstack(html_components['Embedding'])).flatten()\n",
      "/var/folders/r_/7p_x_zfn6m17765l8kqlmk9c0000gn/T/ipykernel_43908/1083413926.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  css_styles['Similarity'] = cosine_similarity(query_embedding, np.vstack(css_styles['Embedding'])).flatten()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the unified data file\n",
    "file_path = \"/Users/smeetsheth/Documents/Data 298B/RAG Implemenation/CSV Files/unified_data_with_embeddings.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the 'Embedding' column from string to list\n",
    "data['Embedding'] = data['Embedding'].apply(lambda x: np.array(eval(x)))\n",
    "\n",
    "# Load SBERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define a sample query\n",
    "query = \"ecommerce Generate a responsive navigation bar with call to action button\"\n",
    "\n",
    "# Generate embedding for the query\n",
    "query_embedding = model.encode(query).reshape(1, -1)\n",
    "\n",
    "# Separate data by Source_Type\n",
    "instructions = data[data['Source_Type'] == 'Instruction']\n",
    "html_components = data[data['Source_Type'] == 'HTML_Component']\n",
    "css_styles = data[data['Source_Type'] == 'CSS_Style']\n",
    "\n",
    "# Compute cosine similarity for each source type\n",
    "instructions['Similarity'] = cosine_similarity(query_embedding, np.vstack(instructions['Embedding'])).flatten()\n",
    "html_components['Similarity'] = cosine_similarity(query_embedding, np.vstack(html_components['Embedding'])).flatten()\n",
    "css_styles['Similarity'] = cosine_similarity(query_embedding, np.vstack(css_styles['Embedding'])).flatten()\n",
    "\n",
    "# Weighted average of similarities for related components\n",
    "weights = {'Instruction': 0.5, 'HTML_Component': 0.3, 'CSS_Style': 0.2}\n",
    "\n",
    "# Initialize a dictionary to store combined similarity scores\n",
    "combined_scores = {}\n",
    "\n",
    "# Combine similarity scores by ID\n",
    "for idx, row in instructions.iterrows():\n",
    "    template_id = row['Source_ID']  # Assuming Source_ID links Instruction, HTML, and CSS\n",
    "    instruction_score = row['Similarity']\n",
    "    \n",
    "    # Get related HTML and CSS scores\n",
    "    html_score = html_components[html_components['Source_ID'] == template_id]['Similarity'].mean() if template_id in html_components['Source_ID'].values else 0\n",
    "    css_score = css_styles[css_styles['Source_ID'] == template_id]['Similarity'].mean() if template_id in css_styles['Source_ID'].values else 0\n",
    "    \n",
    "    # Compute weighted average\n",
    "    combined_score = (\n",
    "        weights['Instruction'] * instruction_score +\n",
    "        weights['HTML_Component'] * html_score +\n",
    "        weights['CSS_Style'] * css_score\n",
    "    )\n",
    "    \n",
    "    combined_scores[template_id] = combined_score\n",
    "\n",
    "# Convert combined scores to a DataFrame for ranking\n",
    "ranked_scores = pd.DataFrame.from_dict(combined_scores, orient='index', columns=['Combined_Similarity'])\n",
    "ranked_scores = ranked_scores.sort_values(by='Combined_Similarity', ascending=False).reset_index()\n",
    "ranked_scores.columns = ['Source_ID', 'Combined_Similarity']\n",
    "\n",
    "# Display top 5 matches\n",
    "print(\"Top 5 Matches:\")\n",
    "print(ranked_scores.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba02f06e",
   "metadata": {},
   "source": [
    "### Creating connection and loading files in chunks for vectorization in AstraDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d8192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cassandra-driver in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (3.29.2)\r\n",
      "Requirement already satisfied: geomet<0.3,>=0.1 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from cassandra-driver) (0.2.1.post1)\r\n",
      "Requirement already satisfied: click in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.0.4)\r\n",
      "Requirement already satisfied: six in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from geomet<0.3,>=0.1->cassandra-driver) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install cassandra-driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48737e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting astrapy\n",
      "  Obtaining dependency information for astrapy from https://files.pythonhosted.org/packages/db/48/684c270724bc3f8d12714556d201aa4610623da919505a6a09e56f50ef6a/astrapy-1.5.2-py3-none-any.whl.metadata\n",
      "  Downloading astrapy-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting deprecation<2.2.0,>=2.1.0 (from astrapy)\n",
      "  Obtaining dependency information for deprecation<2.2.0,>=2.1.0 from https://files.pythonhosted.org/packages/02/c3/253a89ee03fc9b9682f1541728eb66db7db22148cd94f89ab22528cd1e1b/deprecation-2.1.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: httpx[http2]<1,>=0.25.2 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from astrapy) (0.27.0)\n",
      "Collecting pymongo>=3 (from astrapy)\n",
      "  Obtaining dependency information for pymongo>=3 from https://files.pythonhosted.org/packages/29/a2/9643450424bcf241e80bb713497ec2e3273c183d548b4eca357f75d71885/pymongo-4.10.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pymongo-4.10.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: toml<0.11.0,>=0.10.2 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from astrapy) (0.10.2)\n",
      "Collecting uuid6>=2024.1.12 (from astrapy)\n",
      "  Obtaining dependency information for uuid6>=2024.1.12 from https://files.pythonhosted.org/packages/d3/3e/4ae6af487ce5781ed71d5fe10aca72e7cbc4d4f45afc31b120287082a8dd/uuid6-2024.7.10-py3-none-any.whl.metadata\n",
      "  Downloading uuid6-2024.7.10-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: packaging in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from deprecation<2.2.0,>=2.1.0->astrapy) (23.1)\n",
      "Requirement already satisfied: anyio in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from httpx[http2]<1,>=0.25.2->astrapy) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from httpx[http2]<1,>=0.25.2->astrapy) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from httpx[http2]<1,>=0.25.2->astrapy) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from httpx[http2]<1,>=0.25.2->astrapy) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from httpx[http2]<1,>=0.25.2->astrapy) (1.2.0)\n",
      "Collecting h2<5,>=3 (from httpx[http2]<1,>=0.25.2->astrapy)\n",
      "  Obtaining dependency information for h2<5,>=3 from https://files.pythonhosted.org/packages/2a/e5/db6d438da759efbb488c4f3fbdab7764492ff3c3f953132efa6b9f0e9e53/h2-4.1.0-py3-none-any.whl.metadata\n",
      "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/smeetsheth/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx[http2]<1,>=0.25.2->astrapy) (0.14.0)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo>=3->astrapy)\n",
      "  Obtaining dependency information for dnspython<3.0.0,>=1.16.0 from https://files.pythonhosted.org/packages/68/1b/e0a87d256e40e8c888847551b20a017a6b98139178505dc7ffb96f04e954/dnspython-2.7.0-py3-none-any.whl.metadata\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy)\n",
      "  Obtaining dependency information for hyperframe<7,>=6.0 from https://files.pythonhosted.org/packages/d7/de/85a784bcc4a3779d1753a7ec2dee5de90e18c7bcf402e71b51fcf150b129/hyperframe-6.0.1-py3-none-any.whl.metadata\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy)\n",
      "  Obtaining dependency information for hpack<5,>=4.0 from https://files.pythonhosted.org/packages/d5/34/e8b383f35b77c402d28563d2b8f83159319b509bc5f760b15d60b0abf165/hpack-4.0.0-py3-none-any.whl.metadata\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading astrapy-1.5.2-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading pymongo-4.10.1-cp311-cp311-macosx_11_0_arm64.whl (889 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m889.5/889.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading uuid6-2024.7.10-py3-none-any.whl (6.4 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: uuid6, hyperframe, hpack, dnspython, deprecation, pymongo, h2, astrapy\n",
      "Successfully installed astrapy-1.5.2 deprecation-2.1.0 dnspython-2.7.0 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 pymongo-4.10.1 uuid6-2024.7.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade astrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf2d21f",
   "metadata": {},
   "source": [
    "### Connecting to AstraDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3edaf12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Astra DB: []\n"
     ]
    }
   ],
   "source": [
    "from astrapy import DataAPIClient\n",
    "\n",
    "# Initialize the client\n",
    "client = DataAPIClient(\"AstraCS:vjMNnOezJoNIynDjOyHvqOBA:bcd8c820a01ad41a6a456fc1cb31b679bdc2d2248dc1ec0ab1d66ddb3847cc64\")\n",
    "db = client.get_database_by_api_endpoint(\n",
    "  \"https://bb8c1ce4-1426-4fb4-9ee8-a9cfbe118864-us-east-2.apps.astra.datastax.com\"\n",
    ")\n",
    "\n",
    "print(f\"Connected to Astra DB: {db.list_collection_names()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d23b1a",
   "metadata": {},
   "source": [
    "### Creating new collection called 'embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "872145cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'embeddings' created.\n"
     ]
    }
   ],
   "source": [
    "# Create a collection named \"embeddings\"\n",
    "if \"embeddings\" not in db.list_collection_names():\n",
    "    db.create_collection(\"embeddings\")\n",
    "    print(\"Collection 'embeddings' created.\")\n",
    "else:\n",
    "    print(\"Collection 'embeddings' already exists.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4482e5e",
   "metadata": {},
   "source": [
    "### Storing the generated embeddings inside the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f5d4159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All embeddings have been inserted into the 'embeddings' collection.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "# Load your embeddings file\n",
    "file_path = \"/Users/smeetsheth/Documents/Data 298B/RAG Implemenation/CSV Files/unified_data_with_embeddings.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the 'Embedding' column from string to a Python list\n",
    "data['Embedding'] = data['Embedding'].apply(lambda x: eval(x))\n",
    "\n",
    "# Insert records into the collection\n",
    "for _, row in data.iterrows():\n",
    "    document = {\n",
    "        \"id\": str(uuid.uuid4()),  # Unique identifier\n",
    "        \"source_id\": row[\"ID\"],  # Source ID (Instruction/HTML/CSS)\n",
    "        \"source_type\": row[\"Source_Type\"],  # Instruction, HTML, or CSS\n",
    "        \"text_representation\": row[\"Text_Representation\"],  # Text\n",
    "        \"embedding\": row[\"Embedding\"]  # Embedding as a list\n",
    "    }\n",
    "    db[\"embeddings\"].insert_one(document)  # Corrected access to collection\n",
    "\n",
    "print(\"All embeddings have been inserted into the 'embeddings' collection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23979d53",
   "metadata": {},
   "source": [
    "### Retrieving similar ID's based on the query text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "700d0330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Astra DB: ['embeddings']\n",
      "Top Similar Documents:\n",
      "\n",
      "ID: 6e89f492-e870-4303-8096-d0bd3e9b74cb\n",
      "Similarity: 0.75\n",
      "Text Representation: Create a travel booking website header using HTML and CSS. The header should include a logo, navigation links (Visa, Supplier, API, Contact Us), a login and sign-up section, and a currency selector. Use Manrope font for modern and clean typography, and ensure the layout is responsive for all devices. The header should also include an eye-catching headline and subheadline, with call-to-action buttons and user ratings. Apply flexbox for easy alignment and spacing, emphasizing visual hierarchy and user-centered design principles.\n",
      "\n",
      "ID: c4322a89-74b2-414c-9415-2c341eae8c1b\n",
      "Similarity: 0.75\n",
      "Text Representation: Create a travel booking website header using HTML and CSS. The header should include a logo, navigation links (Visa, Supplier, API, Contact Us), a login and sign-up section, and a currency selector. Use Manrope font for modern and clean typography, and ensure the layout is responsive for all devices. The header should also include an eye-catching headline and subheadline, with call-to-action buttons and user ratings. Apply flexbox for easy alignment and spacing, emphasizing visual hierarchy and user-centered design principles.\n",
      "\n",
      "ID: 6165ca7c-ef1e-4d18-bc4d-47bfd9fffa06\n",
      "Similarity: 0.72\n",
      "Text Representation: Create a header for an adventure tourism website under the Travel & Tours category with a sleek, modern look that includes a logo, navigation bar, search bar, and call-to-action button, ensuring responsive design, minimalistic UI elements, intuitive font selection, and balanced color contrast for optimal user engagement and seamless UX.\n",
      "\n",
      "ID: 6a3c149a-9ff9-46a2-b64a-6b5550f891f7\n",
      "Similarity: 0.71\n",
      "Text Representation: Create a header of a travel booking website, featuring a modern, visually captivating look. Include the logo, navigation links, a prominent search bar for location, check-in, and guest filters, and a call-to-action for listing properties. Ensure a responsive layout, smooth typography, gradient overlays, and intuitive UI/UX elements to enhance user engagement and streamline the booking experience.\n",
      "\n",
      "ID: 709e1f01-73b0-4241-a707-8c716d6d406a\n",
      "Similarity: 0.70\n",
      "Text Representation: Create a header for a travel website in the bookings subcategory, featuring a clean, inviting layout with a responsive navigation bar. Include HTML elements for logo, \"Home,\" \"Book Now,\" \"Packages,\" and \"Popular Places,\" alongside a prominent \"Join Us\" button styled with rounded corners, box-shadow, and hover effects. Use Aclonica and Inter fonts for aesthetic balance and user-centric navigation.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# Import DataAPIClient\n",
    "from astrapy import DataAPIClient\n",
    "\n",
    "# Initialize the client\n",
    "client = DataAPIClient(\"AstraCS:vjMNnOezJoNIynDjOyHvqOBA:bcd8c820a01ad41a6a456fc1cb31b679bdc2d2248dc1ec0ab1d66ddb3847cc64\")\n",
    "db = client.get_database_by_api_endpoint(\n",
    "  \"https://bb8c1ce4-1426-4fb4-9ee8-a9cfbe118864-us-east-2.apps.astra.datastax.com\"\n",
    ")\n",
    "\n",
    "print(f\"Connected to Astra DB: {db.list_collection_names()}\")\n",
    "# Define your collection name and get the collection\n",
    "collection_name = \"embeddings\"\n",
    "collection = db.get_collection(collection_name)\n",
    "\n",
    "# Fetch all documents from the Astra DB collection\n",
    "documents = list(collection.find({}))  # This returns all documents in the collection\n",
    "\n",
    "# If embeddings are stored as strings, convert them to lists\n",
    "for doc in documents:\n",
    "    if isinstance(doc[\"embedding\"], str):\n",
    "        doc[\"embedding\"] = ast.literal_eval(doc[\"embedding\"])\n",
    "\n",
    "# Load SBERT model\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')  # Use a lightweight SBERT model\n",
    "\n",
    "# Function to retrieve similar documents\n",
    "def retrieve_similar_document(query_text, documents, top_k=3):\n",
    "    try:\n",
    "        # Embed the query\n",
    "        query_embedding = sbert_model.encode([query_text])[0]\n",
    "\n",
    "        # Extract embeddings and document IDs\n",
    "        embeddings = np.array([doc[\"embedding\"] for doc in documents])\n",
    "        ids = [doc[\"id\"] for doc in documents]\n",
    "        texts = [doc[\"text_representation\"] for doc in documents]\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        similarities = cosine_similarity([query_embedding], embeddings).flatten()\n",
    "\n",
    "        # Get top K most similar documents\n",
    "        top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "        results = [{\"id\": ids[i], \"similarity\": float(similarities[i]), \"text_representation\": texts[i]} for i in top_indices]\n",
    "\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error during retrieval: {e}\")\n",
    "        return []\n",
    "\n",
    "# Sample query text\n",
    "query_text = \"Design a modern header for a travel website with a minimalist layout.\"\n",
    "\n",
    "# Retrieve top 5 similar documents\n",
    "results = retrieve_similar_document(query_text, documents, top_k=5)\n",
    "\n",
    "# Display the results\n",
    "print(\"Top Similar Documents:\")\n",
    "for result in results:\n",
    "    print(f\"\\nID: {result['id']}\")\n",
    "    print(f\"Similarity: {result['similarity']:.2f}\")\n",
    "    print(f\"Text Representation: {result['text_representation']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b7141",
   "metadata": {},
   "source": [
    "### Function to retrieve relevant info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4736e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Similar Documents for new query:\n",
      "\n",
      "ID: fbeeb286-a4c0-4b7a-b3f7-0dd9aa9f0cf4\n",
      "Similarity: 0.53\n",
      "Text Representation: Create a header of a non-profit organization website with a clean, inclusive design that highlights social advocacy. Include a navigation bar with sections like Home, About, Services, Blogs, and Contact. Use visually engaging HTML and CSS components like transparent background overlays, hero images, call-to-action buttons, and accessible typography to enhance user experience and engagement.\n",
      "\n",
      "ID: 83403101-2cd7-44ca-83a3-56de71ce5e76\n",
      "Similarity: 0.52\n",
      "Text Representation: Create a header of a Social Media Management Website showcasing a modern and vibrant interface. Utilize HTML for a structured layout, including navigation, banners, and call-to-action buttons. Implement CSS to ensure responsiveness, color gradients, animations, and bold typography. Prioritize accessibility, intuitive navigation, visual hierarchy, and clean UI components to enhance user engagement, embodying solid UX principles in a dynamic, user-centric experience.\n",
      "\n",
      "ID: c3f6b828-ba72-4b05-8a5e-c8922e9a1b0e\n",
      "Similarity: 0.51\n",
      "Text Representation: Selector: .social-links-icon, Properties: position: absolute; height: 3.59%; width: 21.86%; top: 96.33%; right: 78.14%; bottom: 0.08%; left: 0%; max-width: 100%; overflow: hidden; max-height: 100%, Context: General styling for .social-links-icon..\n",
      "\n",
      "ID: 137488c9-0060-4e0f-86a9-3ff74f34223d\n",
      "Similarity: 0.49\n",
      "Text Representation: Selector: .social-icons, Properties: position: absolute; top: 37px; left: 27px; width: 300.1px; height: 60.4px, Context: General styling for .social-icons..\n",
      "\n",
      "ID: 47c81426-5e44-4cb5-9c1f-ebc5d95737cd\n",
      "Similarity: 0.49\n",
      "Text Representation: Selector: .social-media-follow-us, Properties: position: absolute; top: 9px; left: 1092px; width: 188px; height: 32px, Context: General styling for .social-media-follow-us..\n"
     ]
    }
   ],
   "source": [
    "# New query text\n",
    "query_text = \"Create a footer section with social media icons and contact information.\"\n",
    "\n",
    "# Call the retrieval function with the new query\n",
    "new_results = retrieve_similar_document(query_text, documents, top_k=5)\n",
    "\n",
    "# Print the new results\n",
    "print(\"Top Similar Documents for new query:\")\n",
    "for result in new_results:\n",
    "    print(f\"\\nID: {result['id']}\")\n",
    "    print(f\"Similarity: {result['similarity']:.2f}\")\n",
    "    print(f\"Text Representation: {result['text_representation']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3298d409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b4249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
